<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Mel Frequency Cepstral Coefficients | Devnith Wijesinghe </title> <meta name="author" content="Devnith Wijesinghe"> <meta name="description" content="An article originally published in ECarrier Magazine 2024 April Issue"> <meta name="keywords" content="devnith, academic, machine-learning, deep-learning, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8E%93&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://devnithw.github.io/blog/2024/mfcc/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bf50d6d9dd867d3e0f3b0add94449649"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Devnith </span> Wijesinghe </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Mel Frequency Cepstral Coefficients</h1> <p class="post-meta"> May 08, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> deep-learning</a>   <a href="/blog/tag/signal-processing"> <i class="fa-solid fa-hashtag fa-sm"></i> signal-processing</a>     ·   <a href="/blog/category/article"> <i class="fa-solid fa-tag fa-sm"></i> article</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="mfccs--looking-beyond-the-spectrum-of-human-speech">MFCCs : Looking Beyond the Spectrum of Human Speech</h2> <p><code class="language-plaintext highlighter-rouge">This article was originally published on ECarrier Magazine April 2024 Issue, the official magazine of the Department of Electronic and Telecommunication Engineering, University of Moratuwa.</code></p> <p>Read the original article on the magazine <a href="https://ent.uom.lk/e-carrier-magazine/" rel="external nofollow noopener" target="_blank">here</a></p> <p>The Fourier Transform, a convenient technique to determine the frequency components of a signal, serves as one of the primary methods to extract features of an audio signal. However, with the advancement of the signal processing domain, more sophisticated methods such as short-time Fourier transform (STFT) and wavelet transform have been developed. In this article, we demonstrate one such evolved technique named “mel-frequency cepstral coefficients” (MFCC), which is adapted particularly for speech recognition tasks as a competent feature extractor. Furthermore, we delve into an effective application of this technique for speaker recognition at the IEEE Signal Processing Cup 2024 competition.</p> <h2 id="feature-extractors-the-datasheet-of-signals">Feature Extractors: The Datasheet of Signals</h2> <p>Before tackling what MFCC practically means or its derivation, we first consider the necessity of such a tool. Simply put, a feature extractor identifies certain qualities of a signal, similar to how characteristics like age, height, weight and gender describe a human. They extract key features of an audio signal, like its power, frequencies and rate of change. A trivially simple feature extractor of an audio signal is its root mean square value. This tells us about the power contained within the signal. The zero-crossing rate is another such primary feature. This is a measurement of how fast the signal changes. It is a widely used metric in speech recognition and music information retrieval. Both these tools extract features of the signal in the time domain. However, integral transforms such as the Fourier transform (FT) enable us to investigate the domain of frequency, which unravels new features. The FT, or its primary derivative, power spectral density, encapsulates entirely the frequency components included in the signal and their relative power. However, by converting to the frequency domain, we lose temporal information. As a solution, we mediate the trade-off and localise the signal both in time and frequency by taking the STFT. The STFT, commonly known as the spectrogram, of a speech signal is shown in Figure 1.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/mfcc_comp.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="blood sample image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 1 - Spectrogram of a speech signal </div> <p>This is a map of which frequencies are present at which time, hence a better feature extractor for speech signal processing. Usually, this is depicted using a figure more commonly known as a spectrogram. But what is the significance and superiority of MFCC when it comes to speech signal processing?</p> <h2 id="mel-scale-extracting-human-voice-through-math">Mel Scale: Extracting Human Voice Through Math</h2> <p>It was found that, by taking the spectrum of a spectrum, the periodic structures of the frequency spectrum can be visualised. This tool is sensitive to the low-frequency periodic excitation produced in the human vocal cords and the formant filtering which the voice signal is subjected to in the larynx. This approach to frequency domain analysis, cleverly named as the cepstrum (anagram for spectrum), opened up a newfound domain in signal processing known as cepstral analysis. The exact formula for the cepstrum is as follows,</p> \[C_p = |\mathcal{F}\{log(|\mathcal{F}\{f(t)\}|^2)\}|^2\] <p>Moreover, it was found that by interfering at the log-scaling stage, the cepstrum could be made more sensitive to human voice by taking the mel-scale instead of simply the log-scale. The mel-scale is a perceptual scale of pitches, which, when used to scale the spectrum coefficients, results in a better representation of the cepstrum; and thus, we obtain the mel-frequency cepstrum. The formula for the mel-scale is as follows.</p> \[f = 700 (10^{\frac{m}{2595}} - 1)\] <p>The detailed process of calculating the cepstrum involves applying a triangular filter-bank and several other technical details.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/mfcc_graph.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="blood sample image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 2 - MFCC of a speech signal </div> <p>Next, we consider how to put the MFCC to good use in speech signal processing tasks. The next section builds on our experience from Signal Processing Cup 2024 as a case study to outline how MFCC can be integrated with deep learning techniques to build a speaker recognition inferencing system.</p> <h2 id="robovox-challenge-the-synergy-of-mfcc-and-deep-neural-networks">Robovox Challenge: The Synergy of MFCC and Deep Neural Networks</h2> <p>The main task of the Signal Processing Cup 2024, organised by the IEEE Signal Processing Society, involved screening samples of noisy voice recordings from different speakers and identifying which speaker each recording belongs to from a pool of 71 speakers. During our attempt to provide a solution to this classification task, we applied the technique of extracting MFCC from the audio samples and feeding them into a deep neural network (DNN) to train it. Neural networks are a popular deep learning method where the model learns to identify features in the given data by itself. Therefore, when a feature extractor [3] of an audio sample (such as STFT or MFCC) is fed into a DNN model, it learns to create a feature space, known as an embedding, from several such samples of audio. That is, when given a unique voice recording of a speaker, the model maps it to a certain point on a feature space (similar to a vector space) unique to that speaker. We can force the model to map recordings of similar voices to the same point, by selecting an appropriate loss function. During our implementation, we architectured a popular DNN structure known as a bidirectional long short-term memory with triplet cosine loss as the loss function. This loss function relies on Cosine distance, a popular metric of similarity in a vector embedding context. Using the speaker embedding we formulated using this approach, we were able to accurately do inferences on new data and classify which speaker each recording belonged to.</p> <p>In conclusion, MFCCs prove to be versatile tools in speech recognition. They are a clever method of extracting features like pitch, tone, and the nature of utterances from the human voice. Moreover, this signal processing technique, when paired with modern data-driven learning methods such as deep learning, can help solve a variety of problems related to speech data processing.</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Devnith Wijesinghe. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>