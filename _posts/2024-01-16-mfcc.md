---
layout: post
title: Mel Frequency Cepstral Coefficients
date: 2022-08-02 08:57:00-0400
description: An article originally published in ECarrier Magazine 2024 April Issue
tags: kaggle deep-learning computer-vision jupyter
categories: tutorial
featured: true

giscus_comments: false
related_posts: false
---

## MFCCs : Looking Beyond the Spectrum of Human Speech

`This article was originally published on ECarrier Magazine April 2024 Issue, the official magazine of the Department of Electronic and Telecommunication Engineering, University of Moratuwa. View the magazine [here](https://ent.uom.lk/e-carrier-magazine/) `


The Fourier Transform, a convenient technique to determine the frequency components of a signal, serves as one of the primary methods to extract features of an audio signal. However, with the advancement of the signal processing domain, more sophisticated methods such as short-time Fourier transform (STFT) and wavelet transform have been developed. In this article, we demonstrate one such evolved technique named “mel-frequency cepstral coefficients” (MFCC), which is adapted particularly for speech recognition tasks as a competent feature extractor. Furthermore, we delve into an effective application of this technique for speaker recognition at the IEEE Signal Processing Cup 2024 competition.

## Feature Extractors: The Datasheet of Signals

Before tackling what MFCC practically means or its derivation, we first consider the necessity of such a tool. Simply put, a feature extractor identifies certain qualities of a signal, similar to how characteristics like age, height, weight  and gender describe a human. They extract key features of an audio signal, like its power, frequencies and rate of change. A trivially simple feature extractor of an audio signal is its root mean square value. This tells us about the power contained within the signal. The zero-crossing rate is another such primary feature. This is a measurement of how fast the signal changes. It is a widely used metric in speech recognition and music information retrieval. Both these tools extract features of the signal in the time domain. However, integral transforms such as the Fourier transform (FT) enable us to investigate the domain of frequency, which unravels new features. The FT, or its primary derivative, power spectral density, encapsulates entirely the frequency components included in the signal and their relative power. However, by converting to the frequency domain, we lose temporal information. As a solution, we mediate the trade-off and localise the signal both in time and frequency by taking the STFT. The STFT, commonly known as the spectrogram, of a speech signal is shown in Figure 1.
